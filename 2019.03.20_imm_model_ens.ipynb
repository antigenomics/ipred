{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, gc\n",
    "from tqdm import tqdm, tqdm_notebook, tqdm_pandas\n",
    "from tqdm import trange\n",
    "import time\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool, Process\n",
    "\n",
    "import itertools\n",
    "from modules.kidera import score_positions, score_sequence\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/dataset.csv'\n",
    "destination = ''\n",
    "num_cores = 40\n",
    "num_partitions = 120\n",
    "features = [\"helix.bend.pref\", \"side.chain.size\",\\\n",
    "        \"extended.str.pref\", \"hydrophobicity\", \"double.bend.pref\", \"partial.spec.vol\",\\\n",
    "        \"flat.ext.pref\", \"occurrence.alpha.reg\", \"pK.C\", \"surrounding.hydrop\"]\n",
    "\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    with Pool(num_cores) as pool:\n",
    "        df = pd.concat(pool.map(func, df_split))\n",
    "    return df\n",
    "\n",
    "def score_kidera(df_split):\n",
    "    return df_split.apply(lambda s: score_sequence(s))\n",
    "\n",
    "\"\"\"\n",
    "inds = np.permutation(15000000)\n",
    "inds записываешь в файл\n",
    "итерация один\n",
    "df = pd.read_csv()\n",
    "df = df.loc[inds[:10**6],].reset_index(drop=True)\n",
    "итерация два\n",
    "df = pd.read_csv()\n",
    "df = df.loc[inds[1*10**6:2*10**6],].reset_index(drop=True)\n",
    "\"\"\"\n",
    "\n",
    "def load_data(path):\n",
    "    idf1 = pd.read_csv(path)\n",
    "    idf1 = idf1[['Epitope', 'Immunogenicity']]\n",
    "    np.random.seed(42)\n",
    "    high = 15000000\n",
    "    size = 1000000\n",
    "    low = 30000\n",
    "    rand = np.random.randint(low=low, high=high, size=size)\n",
    "    pos = np.array([i for i in range(low)])\n",
    "    inds = np.concatenate((pos, rand))\n",
    "    idf1 = idf1.iloc[inds].reset_index(drop=True)\n",
    "    idf2 = parallelize_dataframe(idf1.Epitope, score_kidera)\n",
    "#     idf2 = idf1.Epitope.apply(lambda s: score_sequence(s))\n",
    "    idf = pd.concat([idf1, idf2], axis=1)\n",
    "\n",
    "    idf.columns = ['Epitope', 'Immunogenicity'] + features\n",
    "    idf.Immunogenicity = idf.Immunogenicity.map({'immunogenic': 1, 'non-immunogenic': 0,\n",
    "                                             'Positive': 1, 'Negative': 0})\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idf = load_data(path)\n",
    "\n",
    "# X = idf[features].values\n",
    "# y = idf['Immunogenicity'].values\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1008414\n",
       "1      21586\n",
       "Name: Immunogenicity, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf.Immunogenicity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21586,), (1008414,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_ind = idf[idf['Immunogenicity']==1].index\n",
    "neg_ind = idf[idf['Immunogenicity']==0].index\n",
    "pos_ind.shape, neg_ind.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idf.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_data():\n",
    "    training_ind = np.append(pos_ind[5000:], np.random.choice(neg_ind, 16586))\n",
    "    data = idf[features].values[training_ind]\n",
    "    target = idf['Immunogenicity'].values[training_ind]\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train = bootstrap_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.logspace(start=4, stop=10, num=7, base=2)]\n",
    "max_features = [\"auto\", \"log2\", None]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features}\n",
    "#                'max_depth': max_depth}\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_features': 'log2', 'n_estimators': 1024}, 0.85953213553599417)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = StratifiedShuffleSplit(n_splits=5, test_size=0.5),\n",
    "                               verbose=0, random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "rf_random.best_params_, rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = []\n",
    "\n",
    "for i in tqdm_notebook(range(10)):\n",
    "    rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid,\n",
    "                               n_iter = 20, cv = StratifiedShuffleSplit(n_splits=5, test_size=0.5),\n",
    "                               verbose=0, random_state=42, n_jobs = -1)\n",
    "\n",
    "    X_train, y_train = bootstrap_data()\n",
    "    \n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    clf.append(rf_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_test_data():\n",
    "    training_ind = np.append(pos_ind[:5000], np.random.choice(neg_ind, 5000))\n",
    "    data = idf[features].values[training_ind]\n",
    "    target = idf['Immunogenicity'].values[training_ind]\n",
    "    return data, target, sequences\n",
    "\n",
    "X_test, y_test = make_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score is 0.812\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.98      0.84      5000\n",
      "          1       0.97      0.64      0.77      5000\n",
      "\n",
      "avg / total       0.85      0.81      0.81     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats.mstats import gmean\n",
    "def predict_ens(clf):\n",
    "    res = []\n",
    "    for c in clf:\n",
    "        res.append(c.predict_proba(X_test)[:,1])\n",
    "    res = np.stack(res, axis=0)\n",
    "    fin = gmean(res, axis=0)\n",
    "    return [0 if i <.5 else 1 for i in fin]\n",
    "\n",
    "scores = predict_ens(clf)\n",
    "print(\"roc auc score is {:.3}\".format(roc_auc_score(y_test, scores)))\n",
    "print(classification_report(y_test, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['output/ensemble.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(clf, \"output/ensemble.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
