{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magics\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, gc\n",
    "from tqdm import tqdm, tqdm_notebook, tqdm_pandas\n",
    "from tqdm import trange\n",
    "import time\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "\n",
    "from multiprocessing import Pool, Process\n",
    "\n",
    "import itertools\n",
    "from modules.aa_properties import score_hydrophobicity_sequence, score_positions, score_sequence\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa =   ['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
    "ignore = [\"*\", \"U\", \"X\"]\n",
    "viruses = ['CMV_StrainAD169', 'YFV_Strain17D', 'HIV-1_StrainHXB2', 'HCV_StrainIsolateH', 'EBV_StrainAG876']\n",
    "bacteria = ['SHGLsonnei', 'SLMLenteritidis', 'MYPLpneumoniae', 'MYBTsmegmatis', 'SLMLtyphimurium', \n",
    "            'YERSpseudotuberculosis', 'YERSenterocolitica', 'CLMDtrachomatis', 'MYPLsynoviae', 'KLEBpneumoniae',\n",
    "            'CPBTjejuni', 'SHGLflexneri', 'CLOSdificile']\n",
    "kidera = [\"helix.bend.pref\", \"side.chain.size\",\n",
    "           \"extended.str.pref\", \"hydrophobicity\", \"double.bend.pref\", \"partial.spec.vol\",\n",
    "           \"flat.ext.pref\", \"occurrence.alpha.reg\", \"pK.C\", \"surrounding.hydrop\"]\n",
    "fts = ['ft1', 'ft2', 'ft3', 'ft4', 'ft5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdict = {}\n",
    "for key in os.listdir(\"data/fasta/\"):\n",
    "    if key.startswith(\"UP0\"):\n",
    "        fdict[key] = \"Human\"\n",
    "    else:\n",
    "        fdict[key] = key.strip(\"strain.fasta\").strip(\"_\")\n",
    "        \n",
    "def aa_prot_count(args):\n",
    "    path, species = args\n",
    "    record_dict = SeqIO.index(\"data/fasta/\" + path, \"fasta\")\n",
    "    df = pd.DataFrame(columns=['species', 'protein']+aa)\n",
    "    aa_dict  = Counter()\n",
    "    for key in record_dict.keys():\n",
    "        aa_dict = aa_dict + Counter(record_dict[key].seq)\n",
    "        for amino in list(aa_dict):\n",
    "            if amino in ignore:\n",
    "                del aa_dict[amino]\n",
    "        df1 = pd.DataFrame.from_dict(aa_dict, orient='index').T\n",
    "        df1['species'] = species\n",
    "        df1['protein'] = key\n",
    "        df1['prot_len'] = sum(aa_dict.values())\n",
    "        df = pd.concat([df, df1])\n",
    "    return df\n",
    "    \n",
    "def aa_kidera(args):\n",
    "    path, species = args\n",
    "    record_dict = SeqIO.index(\"data/fasta/\" + path, \"fasta\")\n",
    "    df = pd.DataFrame(columns=['species', 'protein']+kidera)\n",
    "    for key in record_dict.keys():\n",
    "        d = score_sequence(record_dict[key].seq, norm=True)\n",
    "        df1 = pd.DataFrame(d).T\n",
    "        df1.columns = kidera\n",
    "        df1['species'] = species\n",
    "        df1['protein'] = key\n",
    "        df = pd.concat([df, df1])\n",
    "    return df\n",
    "\n",
    "def aa_hydrophobicity(args):\n",
    "    path, species = args\n",
    "    record_dict = SeqIO.index(\"data/fasta/\" + path, \"fasta\")\n",
    "    df = pd.DataFrame(columns=['species', 'protein', 'hydrophobicity'])\n",
    "    for key in record_dict.keys():\n",
    "        df1 = pd.DataFrame.from_dict({\n",
    "                'hydrophobicity': score_hydrophobicity_sequence(record_dict[key].seq, norm=True),\n",
    "                'species': species,\n",
    "                'protein': key\n",
    "            }, orient='index').T\n",
    "        df = pd.concat([df, df1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=len(fdict)) as pool:\n",
    "    result = pool.map(aa_prot_count, fdict.items())\n",
    "\n",
    "pdf = pd.concat(result, axis=0)\n",
    "pdf = pdf.fillna(0)\n",
    "pdf = pdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.shape, pdf.drop_duplicates(subset=aa).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_aa_freq(row):\n",
    "    return row[aa] / row['prot_len']\n",
    "df = pdf.apply(lambda row: count_aa_freq(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['protein', 'species']] = pdf[['protein', 'species']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_name(name):\n",
    "    if name in viruses:\n",
    "        return 'virus'\n",
    "    elif name in bacteria:\n",
    "        return 'bacterium'\n",
    "    elif name in 'Human':\n",
    "        return 'human'\n",
    "\n",
    "def cast_pca(df, n_comp, subset=aa):\n",
    "    pca = PCA(n_components=n_comp)\n",
    "\n",
    "    pctd = pca.fit_transform(df[subset])\n",
    "    pcdf = pd.DataFrame(data = pctd, columns = ['pc' + str(i) for i in range(1,n_comp+1)])\n",
    "    pcdf['species'] = df.species\n",
    "\n",
    "    pcdf.species = pcdf.species.apply(lambda x: group_name(x))\n",
    "    return pcdf, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcdf, pca = cast_pca(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "evr = pca.explained_variance_ratio_\n",
    "plt.plot([i for i in range(1, len(evr)+1)], np.cumsum(evr), 'ro')\n",
    "# padding = 1 + 0.1 *  len(evr)\n",
    "# ax.set_xlim(1 - padding, len(evr) + padding)\n",
    "ax.set_title('Variance explained by new factors', fontsize=16)\n",
    "ax.set_xlabel('Factors', fontsize=16)\n",
    "ax.set_ylabel('Variance explained', fontsize=16)\n",
    "ax.set_ylim(0, 1.05);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(evr, columns=['ExplVar']).plot.bar(figsize=(8,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewAAFactors = pca.components_[:5]\n",
    "NewAAFactors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfactordf = pd.DataFrame(NewAAFactors.T, columns=fts, index=aa)\n",
    "myfactordf.to_csv(\"modules/NewAAFactors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.scatterplot(ax=ax, x='pc2', y='pc1', hue='species', data=pcdf, s=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(pcdf):\n",
    "    fig = plt.figure(figsize = (6,6))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('PC1', fontsize = 15)\n",
    "    ax.set_ylabel('PC2', fontsize = 15)\n",
    "    ax.set_title('PCA', fontsize = 20)\n",
    "\n",
    "    targets = pcdf.species.unique()\n",
    "    colours = ['r', 'g', 'b']\n",
    "    for target, colour in zip(targets,colours):\n",
    "        indicesToKeep = pcdf['species'] == target\n",
    "        ax.scatter(pcdf.loc[indicesToKeep, 'pc1']\n",
    "                   , pcdf.loc[indicesToKeep, 'pc2']\n",
    "                   , c = colour\n",
    "                   , s = 50)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "    \n",
    "plot_pca(pcdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df[~df['species'].isin(['SLMLenteritidis', 'EBV_StrainAG876'])]\n",
    "fdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.species = fdf.species.apply(lambda x: group_name(x))\n",
    "di = {'virus': 0, 'bacterium': 0, 'human': 1}\n",
    "fdf.replace({'species': di}, inplace=True)\n",
    "fdf[['species', 'protein']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(probability=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca.transform(fdf[aa])[:,0:5], \n",
    "                                                    fdf['species'].values, \n",
    "                                                    test_size=.25)\n",
    "\n",
    "scores = cross_val_score(clf, X=X_train, y=y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump(clf, \"modules/hum_clf.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[df['species'].isin(['SLMLenteritidis', 'EBV_StrainAG876', 'Human'])]\n",
    "test_df['species'] = test_df.species.apply(lambda x: group_name(x))\n",
    "test_df.replace({'species': di}, inplace=True)\n",
    "X_ultratest = pca.transform(test_df[aa])[:,0:5]\n",
    "y_ultratest = test_df.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test), labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_ultratest, clf.predict(X_ultratest), labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca.transform(fdf[aa])[:,0:5], \n",
    "                                                    fdf['species'].values, \n",
    "                                                    test_size=.25)\n",
    "\n",
    "scores = cross_val_score(clf, X=X_train, y=y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf, \"modules/hum_clf.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test), labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_ultratest, clf.predict(X_ultratest[:,0:5]), labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## New Factors and Kidera factors correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kid = pd.read_csv('modules/kidera.csv', header=None, names=kidera)\n",
    "from modules.aa_properties import symbol_lookup\n",
    "kid.index = kid.index.map(lambda x: symbol_lookup[x])\n",
    "# kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors.columns = fts\n",
    "fact_df = pd.concat([kid, factors], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(fact_df.corr().loc[fts, kidera].T, annot=True, fmt='.2g')\n",
    "sns.despine(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "sns.heatmap(factors.T, annot=True, fmt='.2g')\n",
    "sns.despine(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's take a look at immunogenic peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.read_csv('data/chowell.csv')\n",
    "cdf = cdf[['peptide', 'Immunogenicity']]\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.Immunogenicity = cdf.Immunogenicity.map({'Positive':1,'Negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = pd.DataFrame(NewAAFactors, columns=aa).T\n",
    "factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_factors(sequence, norm=False):\n",
    "    if norm:\n",
    "        return factors.loc[list(sequence)].sum() / len(sequence)\n",
    "    else:\n",
    "        return factors.loc[list(sequence)].sum()\n",
    "    \n",
    "ndf = pd.concat([cdf, cdf.peptide.apply(lambda s: score_factors(s))], axis=1)\n",
    "ndf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.columns = ['peptide', 'immunogenicity'] + fts\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "sns.scatterplot(x=\"ft1\", y=\"ft2\", hue='immunogenicity', data=ndf);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf.columns = ['peptide', 'immunogenicity'] + fts\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ndf[fts].values, ndf.immunogenicity, test_size=.25)\n",
    "clf = RandomForestClassifier(n_estimators=400)\n",
    "\n",
    "scores = cross_val_score(clf, X=X_train, y=y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 5, verbose=0, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New factors and Kidera facors combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.concat([\n",
    "        cdf,\n",
    "        cdf.peptide.apply(lambda s: score_factors(s)),\n",
    "        cdf.peptide.apply(lambda s: score_sequence(s))\n",
    "    ], axis=1)\n",
    "\n",
    "adf.columns = ['peptide', 'Immunogenicity'] + fts + kidera\n",
    "adf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(adf[fts+kidera].values, adf.Immunogenicity, test_size=.25)\n",
    "clf = RandomForestClassifier(n_estimators=400)\n",
    "\n",
    "scores = cross_val_score(clf, X=X_train, y=y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 5, verbose=0, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kidera alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(adf[kidera].values, adf.Immunogenicity, test_size=.25)\n",
    "clf = RandomForestClassifier(n_estimators=400)\n",
    "\n",
    "scores = cross_val_score(clf, X=X_train, y=y_train, cv=5)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = clf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 5, verbose=0, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SVM self score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_new_factors(args):\n",
    "    path, species = args\n",
    "    record_dict = SeqIO.index(\"data/fasta/\" + path, \"fasta\")\n",
    "    df = pd.DataFrame(columns=['species', 'peptide'])\n",
    "    for key in record_dict.keys():\n",
    "        seq = record_dict[key]\n",
    "        d = pd.Series([seq[i:i+9] for i in range(len(seq)-8)])\n",
    "        df1 = pd.DataFrame(d, columns=['peptide'])\n",
    "        df1['species'] = species\n",
    "        df = pd.concat([df, df1])\n",
    "    fdf = pd.concat([\n",
    "            df,\n",
    "            df.peptide.apply(lambda s: score_factors(s))\n",
    "        ], axis=1)\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=len(fdict)) as pool:\n",
    "    result = pool.map(aa_new_factors, fdict.items())\n",
    "\n",
    "fdf = pd.concat(result, axis=0)\n",
    "fdf = fdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
